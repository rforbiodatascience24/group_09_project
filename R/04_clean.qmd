---
title: "04_clean"
author: "Andreis Marco"
format: html
editor: visual
---

### Load the dataset

```{r}
library("tidyverse")
library("here")
```

```{r}
# verify that the dataset can be loaded successfully
data_path <- here("data/03_dat_selected.csv")
dataset <- read_csv(data_path,
                    na = c("nd", "-", "na"),
                    show_col_types = FALSE)
```

The dataset is divided in metadata columns and microorganism relative abundances. We divide the two dataset to facilitate cleaning:

### Cleaning the metadata

```{r}
metadata <- dataset |>
  select(-starts_with("k__"))

dim_desc(metadata)
```

The wide variety of studies from which the data comes from results in a large number of study-specific metadata this can be observed by plotting the amount of NA present in each of these.

```{r}
valid_counts <- metadata |> 
summarise(across(everything(),
                 ~sum(!is.na(.)))) |> 
pivot_longer(everything(),
             names_to = "column_name",
             values_to = "valid_count")
```

We can see that there is a large amount of columns having many NAs.

The columns having only 278 non-NAs values, are columns specific of the "obesity" dataset.

The columns having only 232 non-NAs values, are columns specific of the "Quin_gut_liver_cirrhosis" dataset.

The columns having only 363 non-NAs values, are columns specific of the "T2D" dataset.

The columns having only 145 non-NAs values, are columns specific of the "WT2D" dataset.

The columns having only 110 non-NAs values, are columns specific of the "metahit" dataset.

The columns having only 981 non-NAs values, are columns specific of the "hmp" dataset.

The columns having only 344 non-NAs values, are columns specific of the "hmp" dataset.

These columns are can be really important for analysis of single datasets, so we have to decide what to do them.

### Decision point

Because of what was said before there are two possible approaches:

1.  keep all the datasets and only mantain the columns which are significant for most of them. This makes it difficult to perform significant analysis on the metadata as not many informations are left. On the other hand we have much more data to study in terms of microbiota.

2.  choose only a single dataset and focus the analysis on that one. This allows us to perform more significant analysis on the metadata and also makes the abundance data smaller, thus making it easier to work with it.

### Approach 1 - We keep all datasets

Even if we are not going to follow this path we still provide an example of what the cleaning of this messier dataset could be done.

We also filter out the column having 0 non-NAs values.

```{r}
dataset_specific_columns <- valid_counts |> 
  filter(valid_count < nrow(metadata)*0.70) |> 
  pull(column_name)

metadata_1 <- metadata |> 
  select(-all_of(dataset_specific_columns))
```

```{r}
valid_counts <- metadata_1 |> 
summarise(across(everything(),
                 ~sum(!is.na(.)))) |> 
pivot_longer(everything(),
             names_to = "column_name",
             values_to = "valid_count")

valid_counts |> 
  filter(valid_count != nrow(metadata_1))
```

Even with these approach we still some columns with a varying number of non-NAs values.

```{r}
metadata_1 |> 
  filter(is.na(subjectID))

metadata_1 <- metadata_1 |> 
  filter(!is.na(subjectID))
```

We find that in the t2dmeta_long there are 19 samples are do not have any subjectID and are also missing a lot of metadata, this coincide with the hypothesis of these being the product of some error during the CSV production as by removing them we are able to perfectly match the number of samples expected for the t2d dataset (as found in during data selection).

Now we investigate the remaining data columns having NAs.

```{r}
metadata_1 |> 
  filter(is.na(gender))
```

For `gender` we see that the samples not having a value belong to the WT2D or to the Chatelier_gut_obesity datasets. For the former we can verify by looking at the original paper that all the samples are taken from females, unfortunately the data is not recorded for the latter.

```{r}
metadata_1 <- metadata_1 |> 
  mutate(gender = ifelse(dataset_name == "WT2D",
                         "female", gender))
```

Moving on to the country column

```{r}
metadata_1 |> 
  filter(is.na(country))
```

We can see that is the hmpii dataset to not have the country registered, this can be solved as the HMP project only took into account samples from citizens of the US, as can be seen by the hmp dataset.

One last check allow us to see that the metadata column are now greatly reduced and only contain the columns having the accepted missing values.

```{r}
valid_counts <- metadata_1 |> 
summarise(across(everything(),
                 ~sum(!is.na(.)))) |> 
pivot_longer(everything(), names_to = "column_name",
             values_to = "valid_count")

valid_counts |> 
  filter(valid_count != nrow(metadata_1))
```

The last cleaning we do is simply to remove data not useful for future analysis

```{r}
metadata_1 <- metadata_1 |> 
  select(-sequencing_technology,
         -pubmedid,
         -`#SampleID`)
```

### Approach 2

To the purpose of the project we decided that focusing our effort in the analysis of only a dataset was better. As it allows to better show what we have learned in the course. Due to the interesting metadata columns we focused on the WT2D dataset.

```{r}
metadata <- dataset |> 
  filter(dataset_name == "WT2D") |> 
  select(-starts_with("k__"))
```

As before we need to get rid of the columns containing to many missing values

```{r}
valid_counts <- metadata |> 
summarise(across(everything(), ~sum(!is.na(.)))) |> 
pivot_longer(everything(), names_to = "column_name", values_to = "valid_count")
```

```{r}
to_remove <- valid_counts |> 
  filter(valid_count != nrow(metadata)) |> 
  pull(column_name)

metadata <- metadata |> 
  select(-to_remove)
```

We remove columns having all the same value for all rows as they do not provide any information

```{r}
metadata <- metadata |>
  select(where(~ n_distinct(.) > 1))
```

We see that the sampleID is just a lower case subjectID for every row, therefore we remove the subjectID.

```{r}
metadata |> 
  mutate(redundant = sampleID == str_to_upper(subjectID)) |> 
  select(redundant) |> 
  unique()

metadata <- metadata |> 
  select(-subjectID)
```

We see that the `classification` column is just another way of classifying the `disease` column with:

-   n (no disease) = ngt (normal glucose tollerance)
-   impaired_glucose_tollerance = igt
-   t2d = t2d (type 2 diabetes)

```{r}
metadata |> 
  select(disease, classification)

metadata <- metadata |>
  select(-classification)
```

### Cleaning the abundance data

```{r}
abundance_data <- dataset |> 
  filter(dataset_name == "WT2D") |> 
  select(starts_with("k__"))
```

The only cleaning we can do on the abundances is that of removing columns that do not contain any data, i.e. columns the species of which is not present in any of the samples.

```{r}
abundance_data <- abundance_data |> 
  select(where(~ sum(.x, na.rm = TRUE) != 0))###
```

### Saving the dataset

Lastly we merge the metadata with the abundance data. We can do it without checking the row corrispondance, as we did not remove any row or alter their order during the cleaning.

```{r}
dataset <- metadata |> 
  bind_cols(abundance_data)
```

```{r}
target_dir <- "../data"

# Create the data folder if it does not exist
if (!file.exists(target_dir)) {
  # Create the folder if it doesn't exist
  dir.create(target_dir, recursive = TRUE)
  }

# save the dataset in the data fodler
write_csv(dataset, str_c(target_dir, "/04_dat_clean.csv"))
```
